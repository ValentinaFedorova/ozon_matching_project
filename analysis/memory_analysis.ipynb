{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.DoubleTensor().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import getsizeof\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186963, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed = pd.read_parquet(\"../data/train_preprocessed/batch_0.parquet\")\n",
    "target = preprocessed[\"target\"]\n",
    "preprocessed = preprocessed.drop(\"target\", axis=1)\n",
    "preprocessed.to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m attributes \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/train/attributes.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# resnet = pd.read_parquet(\"../data/train/resnet.parquet\")\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m text_and_bert \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/train/text_and_bert.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/train/train.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/hackaton/matching-tovarov-5699/venv/lib/python3.11/site-packages/pandas/io/parquet.py:509\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    507\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/hackaton/matching-tovarov-5699/venv/lib/python3.11/site-packages/pandas/io/parquet.py:230\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, use_nullable_dtypes, dtype_backend, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    228\u001b[0m         path_or_handle, columns\u001b[38;5;241m=\u001b[39mcolumns, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    229\u001b[0m     )\n\u001b[0;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mto_pandas_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    233\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m_as_manager(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/hackaton/matching-tovarov-5699/venv/lib/python3.11/site-packages/pyarrow/array.pxi:885\u001b[0m, in \u001b[0;36mpyarrow.lib._PandasConvertible.to_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/hackaton/matching-tovarov-5699/venv/lib/python3.11/site-packages/pyarrow/table.pxi:5002\u001b[0m, in \u001b[0;36mpyarrow.lib.Table._to_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/hackaton/matching-tovarov-5699/venv/lib/python3.11/site-packages/pyarrow/pandas_compat.py:784\u001b[0m, in \u001b[0;36mtable_to_dataframe\u001b[0;34m(options, table, categories, ignore_metadata, types_mapper)\u001b[0m\n\u001b[1;32m    781\u001b[0m columns \u001b[38;5;241m=\u001b[39m _deserialize_column_index(table, all_columns, column_indexes)\n\u001b[1;32m    783\u001b[0m column_names \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mcolumn_names\n\u001b[0;32m--> 784\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable_to_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mext_columns_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _pandas_api\u001b[38;5;241m.\u001b[39mis_ge_v3():\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_dataframe_from_blocks\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "attributes = pd.read_parquet(\"../data/train/attributes.parquet\")\n",
    "# resnet = pd.read_parquet(\"../data/train/resnet.parquet\")\n",
    "text_and_bert = pd.read_parquet(\"../data/train/text_and_bert.parquet\")\n",
    "train = pd.read_parquet(\"../data/train/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_in_gb(var):\n",
    "    size = getsizeof(var)\n",
    "    return size / 2 ** 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.292391447350383\n",
      "3.8826297046616673\n",
      "0.02611852064728737\n"
     ]
    }
   ],
   "source": [
    "print(get_size_in_gb(attributes))\n",
    "print(get_size_in_gb(text_and_bert))\n",
    "print(get_size_in_gb(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Маленький анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    248490\n",
      "1    230133\n",
      "Name: count, dtype: int64\n",
      "target\n",
      "0    62123\n",
      "1    57533\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(train, test_size=0.2, stratify=train.target)\n",
    "print(train.target.value_counts())\n",
    "print(test.target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(drop=True).to_csv(\"../data/train_batched/train.csv\")\n",
    "test.reset_index(drop=True).to_csv(\"../data/train_batched/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variantid1</th>\n",
       "      <th>variantid2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>853088</th>\n",
       "      <td>1434353901</td>\n",
       "      <td>1434351740</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435608</th>\n",
       "      <td>1179662401</td>\n",
       "      <td>1179731979</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212398</th>\n",
       "      <td>1543330364</td>\n",
       "      <td>1385896130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733422</th>\n",
       "      <td>1448912941</td>\n",
       "      <td>1451715340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109444</th>\n",
       "      <td>975589316</td>\n",
       "      <td>1197948269</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624920</th>\n",
       "      <td>386492071</td>\n",
       "      <td>1221313151</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869794</th>\n",
       "      <td>630746406</td>\n",
       "      <td>1169230998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816615</th>\n",
       "      <td>951680945</td>\n",
       "      <td>671264098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640201</th>\n",
       "      <td>768589465</td>\n",
       "      <td>587558046</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109900</th>\n",
       "      <td>785890792</td>\n",
       "      <td>786393866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>478623 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         variantid1  variantid2  target\n",
       "853088   1434353901  1434351740       0\n",
       "435608   1179662401  1179731979       0\n",
       "212398   1543330364  1385896130       0\n",
       "733422   1448912941  1451715340       1\n",
       "1109444   975589316  1197948269       0\n",
       "...             ...         ...     ...\n",
       "624920    386492071  1221313151       1\n",
       "869794    630746406  1169230998       0\n",
       "816615    951680945   671264098       0\n",
       "640201    768589465   587558046       1\n",
       "109900    785890792   786393866       0\n",
       "\n",
       "[478623 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_df_pairs_batches(df: pd.DataFrame, n_batches: int, shuffle: bool = True):\n",
    "    # splits df in given number batches\n",
    "    if shuffle: \n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "    out = []\n",
    "    for part in np.array_split(df.index, n_batches):\n",
    "        out.append(df.iloc[part])\n",
    "    return out\n",
    "\n",
    "def _get_unique_ids(df_pairs: pd.DataFrame):\n",
    "    # gets all unique variantid that are used in df with target\n",
    "    return np.unique(np.concatenate([df_pairs[\"variantid1\"], df_pairs[\"variantid2\"]]))\n",
    "\n",
    "def _get_batch_data(df_pairs: pd.DataFrame, attributes: pd.DataFrame, text_and_bert: pd.DataFrame):\n",
    "    unique_ids = _get_unique_ids(df_pairs)\n",
    "    return attributes[attributes.variantid.isin(unique_ids)], text_and_bert[text_and_bert.variantid.isin(unique_ids)]\n",
    "\n",
    "def split_train(path: str, save_path: str, n_batches: int = 5):\n",
    "    train_pairs = pd.read_parquet(os.path.join(path, \"train.parquet\"))\n",
    "    attributes = pd.read_parquet(os.path.join(path, \"attributes.parquet\"))\n",
    "    text_and_bert = pd.read_parquet(os.path.join(path, \"text_and_bert.parquet\"))\n",
    "\n",
    "    # сплитим на тест и на трейн, считаем, что тест должен влезть в память :)\n",
    "    train, test = train_test_split(train, test_size=0.2, stratify=train.target)\n",
    "    \n",
    "    test.reset_index(drop=True).to_parquet(os.path.join(save_path, \"test.parquet\"))\n",
    "    \n",
    "    # save test\n",
    "    test_atrribute, test_text_and_bert = _get_batch_data(test, attributes, text_and_bert)\n",
    "    test_atrribute.to_parquet(os.path.join(save_path, \"test_atrributes.parquet\"))\n",
    "    test_text_and_bert.to_parquet(os.path.join(save_path, \"test_text_and_bert.parquet\"))\n",
    "    del test_atrribute\n",
    "    del test_text_and_bert\n",
    "    \n",
    "    batches = _split_df_pairs_batches(train, n_batches)\n",
    "    \n",
    "    for i, batch in enumerate(batches):\n",
    "        batch_attribute, batch_text_and_bert = _get_batch_data(batch, attributes, text_and_bert)\n",
    "        batch_attribute.to_parquet(os.path.join(save_path, f\"batch{i}_attributes.parquet\"))\n",
    "        batch_text_and_bert.to_parquet(os.path.join(save_path, f\"batch{i}_text_and_bert.parquet\"))\n",
    "        \n",
    "\n",
    "train = pd.read_parquet(\"../data/train/train.parquet\")\n",
    "batches = _split_df_pairs_batches(train, 5)\n",
    "_batch1 = batches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_unique_ids = _get_unique_ids(_batch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_size_in_gb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m _batch1_attribute \u001b[38;5;241m=\u001b[39m attributes[attributes\u001b[38;5;241m.\u001b[39mvariantid\u001b[38;5;241m.\u001b[39misin(_unique_ids)]\n\u001b[0;32m----> 2\u001b[0m \u001b[43mget_size_in_gb\u001b[49m(_batch1_attribute)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_size_in_gb' is not defined"
     ]
    }
   ],
   "source": [
    "_batch1_attribute = attributes[attributes.variantid.isin(_unique_ids)]\n",
    "get_size_in_gb(_batch1_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458765,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_unique_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  47598998,   47601846,   47613863, ..., 1564722376, 1564723632,\n",
       "       1564724243])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_unique_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13438/96913245.py:2: PerformanceWarning: Resolving the schema of a LazyFrame is a potentially expensive operation. Use `LazyFrame.collect_schema()` to get the schema without this warning.\n",
      "  resnet_pq.schema\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Schema([('variantid', Int64),\n",
       "        ('main_pic_embeddings_resnet_v1', List(List(Float64))),\n",
       "        ('pic_embeddings_resnet_v1', List(List(Float64)))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "resnet_pq = pl.scan_parquet('../data/train/resnet.parquet')\n",
    "resnet_pq.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = resnet_pq.filter(pl.col(\"variantid\").is_in(_unique_ids[:_unique_ids.shape[0] // 2])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_to_parquet(parquet_path: str, df: pd.DataFrame):\n",
    "    if os.path.exists(parquet_path):\n",
    "        # append mode\n",
    "        df.to_parquet(parquet_path, engine=\"fastparquet\", append=True)\n",
    "    else:\n",
    "        # new file\n",
    "        df.to_parquet(parquet_path, engine=\"fastparquet\")\n",
    "\n",
    "pyarrow = result.to_arrow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.lib.Table"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pyarrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variantid: int64\n",
       "main_pic_embeddings_resnet_v1: large_list<item: large_list<item: double>>\n",
       "  child 0, item: large_list<item: double>\n",
       "      child 0, item: double\n",
       "pic_embeddings_resnet_v1: large_list<item: large_list<item: double>>\n",
       "  child 0, item: large_list<item: double>\n",
       "      child 0, item: double"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyarrow.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq_writter = pq.ParquetWriter('../data/tmp.parquet', schema=pyarrow.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229382, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyarrow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq_writter.write_table(pyarrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq_writter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.lib.Table"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pyarrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow._parquet.FileMetaData object at 0x7f9ca4fb34c0>\n",
       "  created_by: parquet-cpp-arrow version 17.0.0\n",
       "  num_columns: 3\n",
       "  num_rows: 458764\n",
       "  num_row_groups: 2\n",
       "  format_version: 2.6\n",
       "  serialized_size: 1889"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquet_file = pq.ParquetFile('../data/tmp.parquet')\n",
    "parquet_file.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecordBatch\n",
      "batch_df:    variantid                      main_pic_embeddings_resnet_v1  \\\n",
      "0   47920382  [[0.8170074820518494, 0.9416620135307312, 0.31...   \n",
      "1   49801845  [[-0.43339717388153076, -0.17318281531333923, ...   \n",
      "2   49853444  [[0.11314830183982849, -0.34010639786720276, -...   \n",
      "3   49893028  [[0.25037717819213867, 0.33753663301467896, 0....   \n",
      "\n",
      "                            pic_embeddings_resnet_v1  \n",
      "0  [[0.20931944251060486, -0.29257065057754517, -...  \n",
      "1                                               None  \n",
      "2                                               None  \n",
      "3                                               None  \n"
     ]
    }
   ],
   "source": [
    "parquet_file = pq.ParquetFile('../data/train/resnet.parquet')\n",
    "pl\n",
    "\n",
    "\n",
    "for batch in parquet_file.iter_batches(batch_size=4):\n",
    "    print(\"RecordBatch\")\n",
    "    batch_df = batch.to_pandas()\n",
    "    print(\"batch_df:\", batch_df)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.083879947662354e-07"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_size_in_gb(batch_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variantid1</th>\n",
       "      <th>variantid2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186963</th>\n",
       "      <td>1504231674</td>\n",
       "      <td>1482740487</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186964</th>\n",
       "      <td>733771694</td>\n",
       "      <td>298403096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186965</th>\n",
       "      <td>1554489495</td>\n",
       "      <td>1480846705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186966</th>\n",
       "      <td>1029342474</td>\n",
       "      <td>426500702</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186967</th>\n",
       "      <td>1331337846</td>\n",
       "      <td>1334075274</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373921</th>\n",
       "      <td>1502158839</td>\n",
       "      <td>1502158904</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373922</th>\n",
       "      <td>1219136532</td>\n",
       "      <td>976312541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373923</th>\n",
       "      <td>1037365436</td>\n",
       "      <td>1037365579</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373924</th>\n",
       "      <td>372116797</td>\n",
       "      <td>949616866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373925</th>\n",
       "      <td>645926350</td>\n",
       "      <td>1543267885</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186963 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        variantid1  variantid2  target\n",
       "186963  1504231674  1482740487       1\n",
       "186964   733771694   298403096       0\n",
       "186965  1554489495  1480846705       1\n",
       "186966  1029342474   426500702       1\n",
       "186967  1331337846  1334075274       0\n",
       "...            ...         ...     ...\n",
       "373921  1502158839  1502158904       0\n",
       "373922  1219136532   976312541       1\n",
       "373923  1037365436  1037365579       0\n",
       "373924   372116797   949616866       1\n",
       "373925   645926350  1543267885       1\n",
       "\n",
       "[186963 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(\"../data/train_batched/batch1.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
